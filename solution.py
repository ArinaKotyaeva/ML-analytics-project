# -*- coding: utf-8 -*-
"""Копия блокнота "hw_3_kaggle.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10goVb1w09efBx7wzVtELH2r41wNSGKvq
"""

from sklearn.metrics import roc_auc_score

y_true = [
    0,
    1,
    1,
    0,
    1
]

y_predictions = [
    0.1,
    0.9,
    0.4,
    0.6,
    0.61
]

roc_auc_score(y_true, y_predictions)

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt

!gdown 1ERwQ5odiK1Zvi1LtjpkzCMUswYsAX8_K  # train.csv
!gdown 1fGw_-RFwvn_LEdt91Jq-7A-wzG6mmH8r  # test.csv
!gdown 199Mt4OYZNaelT83U-HGDsEYs2YcUGQ6y  # submission.csv

data_train = pd.read_csv('./train.csv')
data_test = pd.read_csv('./test.csv')
data_submission = pd.read_csv("./submission.csv")

data_train.head()

data_test.head()

data_submission.head()

num_cols = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent'
]

cat_cols = [
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'HasContractPhone',
    'IsBillingPaperless',
    'PaymentMethod'
]

feature_cols = num_cols + cat_cols
target_col = 'Churn'

data_train.info()

data_test.info()

data_train.isna().sum()

data_test.isna().sum()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


missing_matrix = data_train.isnull()

plt.figure(figsize=(10, 6))
sns.heatmap(missing_matrix, cbar=False, cmap='viridis')
plt.title('Пропущенные значения в DataFrame')
plt.show()

num_cols = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent'
]

cat_cols = [
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'HasContractPhone',
    'IsBillingPaperless',
    'PaymentMethod'
]

feature_cols = num_cols + cat_cols
target_col = 'Churn'

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.figure(figsize = (10, 6))
plt.hist(data_train["ClientPeriod"])
plt.hist(data_train["MonthlySpending"])
plt.title("ClientPeriod and MonthlySpending")
plt.show()

plt.figure(figsize = (10, 6))
plt.hist(data_train["TotalSpent"])
plt.title("TotalSpent")
plt.show()

fig, axes = plt.subplots(nrows=1, ncols=len(cat_cols), figsize=(15, 10))

for i in range(len(cat_cols)):
  axes[i].plot(data_train[cat_cols[i]].value_counts())
  axes[i].set_title(i)

plt.tight_layout()
plt.show()

# YOUR CODE

from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.pipeline import make_pipeline

cat_data_train = data_train[cat_cols]
cat_data_test = data_test[cat_cols]

dummy_features_train = pd.get_dummies(cat_data_train)
dummy_features_test = pd.get_dummies(cat_data_test)

num_data_train = data_train[num_cols]
num_data_test = data_test[num_cols]

data_train.head()

data_test.head()

num_data_train.info()

X_train = pd.concat([num_data_train, dummy_features_train], axis = 1)
X_origin_train = data_train.iloc[:, :-1]

Y_train = data_train["Churn"]

X_test = pd.concat([num_data_test, dummy_features_test], axis = 1)
X_origin_test = data_test.iloc[:, :-1]

print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)

X_train.info()

c = 0

for i in range(5282):
  if X_train[num_cols[-1]][i] == " ":
    c += 1
    X_train.drop(i, inplace=True)
    Y_train.drop(i, inplace = True)
print(c)

c = 0

for i in range(1761):
  if X_test["TotalSpent"][i] == " ":
    c += 1
    X_test.drop(i, inplace=True)
print(c)

X_train["TotalSpent"] = X_train["TotalSpent"].astype(float)
X_test["TotalSpent"] = X_test["TotalSpent"].astype(float)

X_test.info()

scaler = StandardScaler()


X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.fit_transform(X_test[num_cols])

X_train.head()

X_test.head()

X_train.info()

x_train, x_test, y_train, y_test = train_test_split(X_train.values, Y_train.values,
                                                    train_size=0.8,
                                                    random_state=42)

model = LogisticRegressionCV(
    Cs=[100, 10, 1, 0.1, 0.01, 0.001],
    cv=5,
    scoring='roc_auc',
    solver='liblinear',
    penalty='l2',
    refit=True,
    random_state=42,
    max_iter=800,
)
model.fit(x_train, y_train)

print(f"Лучший C: {model.C_[0]}")
y_pred_proba = model.predict_proba(x_test)[:, 1]
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}")

!pip install xgboost -q
!pip install catboost -q

# Бустеры
import catboost # документация: https://catboost.ai/docs
import xgboost

from sklearn.metrics import roc_auc_score, roc_curve

boosting_model0 = xgboost.XGBClassifier(n_estimators=500)

boosting_model0.fit(x_train, y_train)

y_train_predicted = boosting_model0.predict_proba(x_train)[:, 1]
y_test_predicted = boosting_model0.predict_proba(x_test)[:, 1]

train_auc = roc_auc_score(y_train, y_train_predicted)
test_auc = roc_auc_score(y_test, y_test_predicted)

plt.figure(figsize=(10,7))
plt.plot(*roc_curve(y_train, y_train_predicted)[:2], label='train AUC={:.4f}'.format(train_auc))
plt.plot(*roc_curve(y_test, y_test_predicted)[:2], label='test AUC={:.4f}'.format(test_auc))
legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()
legend_box.set_facecolor("white")
legend_box.set_edgecolor("black")
plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))
plt.show()

X_origin_TRAIN, X_origin_TEST, _1, _2 = train_test_split(X_origin_train.values, data_train["Churn"].values,
                                                       train_size=0.8,
                                                       random_state=42)

X_origin_TRAIN.shape

X_origin_TRAIN = pd.DataFrame(X_origin_TRAIN, columns=data_train.iloc[ :, :-1].columns)
X_origin_TEST = pd.DataFrame(X_origin_TEST, columns=data_train.iloc[ :, :-1].columns)

boosting_model = catboost.CatBoostClassifier(n_estimators=200,
                                             cat_features=cat_cols)

boosting_model.fit(X_origin_TRAIN, _1)

y_train_predicted = boosting_model.predict_proba(X_origin_TRAIN)[:, 1]
y_test_predicted = boosting_model.predict_proba(X_origin_TEST)[:, 1]

rain_auc = roc_auc_score(_1, y_train_predicted)
test_auc = roc_auc_score(_2, y_test_predicted)

plt.figure(figsize=(10,7))
plt.plot(*roc_curve(_1, y_train_predicted)[:2], label='train AUC={:.4f}'.format(train_auc))
plt.plot(*roc_curve(_2, y_test_predicted)[:2], label='test AUC={:.4f}'.format(test_auc))
legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()
legend_box.set_facecolor("white")
legend_box.set_edgecolor("black")
plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))
plt.show()

"""# Итог

была проведена полная подготовка датасета. обучены 3 модели с использованием LogisticRegressionCV, xgboost и catboost. лучшую точность показала первая модель с парматером c = 10.(ROC-AUC: 0.844)
"""